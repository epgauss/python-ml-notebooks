{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 784\n",
    "x = tf.placeholder(tf.float32, [None, D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([D, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution from Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf.argmax(y,1) - what we predicted\n",
    "# tf.argmax(y_,1) - correct label\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "See: https://github.com/pilipolio/schibsted-study/blob/master/notebooks/201612_mnist.ipynb\n",
    "\n",
    "### Task\n",
    "* Re-user softmax classification from https://github.com/pilipolio/schibsted-study/blob/master/notebooks/201611_multiclass_classification.ipynb\n",
    "* Define train_X and train_Y from mnist_data.train.images/labels\n",
    "* Calculate the accuracy (ratio of correctly classified labels)\n",
    "* Think about a way to visualise the fitted weights\n",
    "* Improve the accuracy of the naive model by adding non-linear layers (see https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "WIDTH, HEIGHT = (28, 28)\n",
    "\n",
    "# unique_labels = np.unique(mnist.train.labels)\n",
    "unique_labels = 10\n",
    "# print('Train has {} dimensions with {} unique classe: {}'.format(mnist.train.images.shape, len(unique_labels), unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples, D = mnist.train.images.shape\n",
    "C = unique_labels #.shape[0]\n",
    "\n",
    "n_samples, D, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_image(pixels):\n",
    "    plt.imshow(pixels.reshape((WIDTH, HEIGHT)), cmap='Greys', interpolation='None');\n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "\n",
    "show_image(mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = .5\n",
    "n_epochs = 1000\n",
    "display_step = 100\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing weights for each epochs for later visualisation\n",
    "fitted_ws = np.zeros((n_epochs, D * unique_labels))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # batch_xs = mnist.train.images\n",
    "    # batch_ys = mnist.train.labels\n",
    "    _, fitted_w, loss_value, predicted_probs = sess.run(\n",
    "        fetches=[optimizer, W, cross_entropy, y],\n",
    "        feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    fitted_ws[epoch, :] = fitted_w.ravel()\n",
    "    predicted_probs = sess.run(y, feed_dict={x: batch_xs})\n",
    "    predicted_classes = predicted_probs.argmax(axis=1)\n",
    "    n_correct_samples = np.sum(predicted_classes == batch_ys.argmax(axis=1))\n",
    "    percent_correct = round(n_correct_samples / len(predicted_classes) * 100)\n",
    "    \n",
    "    if (epoch) % display_step == 0:\n",
    "        print(\"Epoch: {:4d}, cost={:.4f}, %correct {}\".format(epoch, loss_value, percent_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_images = fitted_ws[-1].reshape((D, 10))\n",
    "show_image(w_images[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv-net solution using TF Slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenet(images):\n",
    "   net = slim.conv2d(images, 20, [5,5], scope='conv1')\n",
    "   net = slim.max_pool2d(net, [2,2], scope='pool1')\n",
    "   net = slim.conv2d(net, 50, [5,5], scope='conv2')\n",
    "   net = slim.max_pool2d(net, [2,2], scope='pool2')\n",
    "   net = slim.flatten(net, scope='flatten3')\n",
    "   net = slim.fully_connected(net, 500, scope='fully_connected4')\n",
    "   net = slim.fully_connected(net, 10, activation_fn=None, scope='fully_connected5')\n",
    "   return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist.train.images.reshape((-1, HEIGHT, WIDTH, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = mnist.train.images.reshape((-1, HEIGHT, WIDTH, 1))\n",
    "net = lenet(images)\n",
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = tf.one_hot(tf.argmax(mnist.train.labels, 1), 10, dtype=tf.int32)\n",
    "loss = slim.losses.softmax_cross_entropy(net, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_dir = './log/train' # Where checkpoints are stored.\n",
    "learning_rate=.001\n",
    "\n",
    "total_loss = slim.losses.get_total_loss()\n",
    "# tf.summary.scalar('losses/total_loss', total_loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "# create_train_op ensures that each time we ask for the loss, the update_ops\n",
    "# are run and the gradients being computed are applied too.\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slim.learning.train(\n",
    "    train_op,\n",
    "    log_dir,\n",
    "    number_of_steps=1,\n",
    "    save_summaries_secs=300,\n",
    "    save_interval_secs=600)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
