{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39638567, -0.14599776],\n",
       "       [ 0.9013021 , -0.2407124 ],\n",
       "       [ 0.57776117,  0.27585888],\n",
       "       [-0.12349987,  0.16445065],\n",
       "       [ 0.94248819,  0.40537047],\n",
       "       [ 0.72268963, -0.55309057],\n",
       "       [-0.44066286,  0.10780501],\n",
       "       [-0.99219823,  0.07880068],\n",
       "       [-0.51341844, -0.56764507],\n",
       "       [ 0.73398495, -0.91276121]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dir().count('sess'):\n",
    "    sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "vocabulary_size = 10\n",
    "embedding_size = 2\n",
    "\n",
    "W_input = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "sess.run(W_input.initializer)\n",
    "\n",
    "W_input.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39638567 -0.14599776]\n",
      " [ 0.9013021  -0.2407124 ]\n",
      " [ 0.57776117  0.27585888]\n",
      " [-0.12349987  0.16445065]\n",
      " [ 0.94248819  0.40537047]\n",
      " [ 0.72268963 -0.55309057]\n",
      " [-0.44066286  0.10780501]\n",
      " [-0.99219823  0.07880068]\n",
      " [-0.51341844 -0.56764507]\n",
      " [ 0.73398495 -0.91276121]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.12349987,  0.16445065], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word = 3\n",
    "output_word = 4\n",
    "\n",
    "print(W_input.eval())\n",
    "tf.nn.embedding_lookup(W_input, input_word).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05107924,  0.10061752, -0.0403597 ,  0.03184319, -0.06993999,\n",
       "         0.24070053,  0.14932929, -0.00373278,  0.18020698,  0.03997286]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_output = tf.Variable(tf.random_uniform([embedding_size, vocabulary_size], -1.0, 1.0))\n",
    "sess.run(W_output.initializer)\n",
    "scores = tf.matmul(tf.nn.embedding_lookup(W_input, [input_word]), W_output).eval()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09788708],\n",
       "       [ 0.10285836],\n",
       "       [ 0.08933342],\n",
       "       [ 0.09602212],\n",
       "       [ 0.08672962],\n",
       "       [ 0.1183251 ],\n",
       "       [ 0.10799281],\n",
       "       [ 0.09266609],\n",
       "       [ 0.1113794 ],\n",
       "       [ 0.09680593]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(tf.nn.softmax(scores)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.nn.sparse_softmax_cross_entropy` not found.\n"
     ]
    }
   ],
   "source": [
    "tf.nn.sparse_softmax_cross_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-01-27 14:59:48--  http://www.cs.cornell.edu/~shuochen/lme/dataset.tar.gz\n",
      "Resolving www.cs.cornell.edu... 132.236.207.20\n",
      "Connecting to www.cs.cornell.edu|132.236.207.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15344424 (15M) [application/x-gzip]\n",
      "Saving to: 'dataset.tar.gz.1'\n",
      "\n",
      "dataset.tar.gz.1    100%[===================>]  14.63M  4.58MB/s    in 3.2s    \n",
      "\n",
      "2017-01-27 14:59:52 (4.58 MB/s) - 'dataset.tar.gz.1' saved [15344424/15344424]\n",
      "\n",
      "x dataset/\n",
      "x dataset/._.DS_Store\n",
      "x dataset/.DS_Store\n",
      "x dataset/README\n",
      "x dataset/yes_big/\n",
      "x dataset/yes_complete/\n",
      "x dataset/yes_small/\n",
      "x dataset/yes_small/song_hash.txt\n",
      "x dataset/yes_small/tag_hash.txt\n",
      "x dataset/yes_small/tags.txt\n",
      "x dataset/yes_small/test.txt\n",
      "x dataset/yes_small/train.txt\n",
      "x dataset/yes_complete/song_hash.txt\n",
      "x dataset/yes_complete/tag_hash.txt\n",
      "x dataset/yes_complete/tags.txt\n",
      "x dataset/yes_complete/test.txt\n",
      "x dataset/yes_complete/train.txt\n",
      "x dataset/yes_big/song_hash.txt\n",
      "x dataset/yes_big/tag_hash.txt\n",
      "x dataset/yes_big/tags.txt\n",
      "x dataset/yes_big/test.txt\n",
      "x dataset/yes_big/train.txt\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.cs.cornell.edu/~shuochen/lme/dataset.tar.gz\n",
    "! tar -xvf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17430147 17277121 17767569 17352501 17567841 17650\r\n",
      "19 456 22 82 120 854 597 20 160 76 415 493 81 29 1\r\n",
      "0 1 2 3 4 5 6 7 8 \r\n",
      "9 10 11 \r\n",
      "12 13 14 15 \r\n"
     ]
    }
   ],
   "source": [
    "! head -5 dataset/yes_small/train.txt | cut -c 1-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .assign\n",
    "* .apply\n",
    "* .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41480 playlists for a total of 175911 songs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[16, 17, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         songs\n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
       "3                  [9, 10, 11]\n",
       "4             [12, 13, 14, 15]\n",
       "5                 [16, 17, 18]\n",
       "6                         [19]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_FAULTY_PLAYLIST = 2\n",
    "playlists = pd.read_csv('dataset/yes_small/train.txt', header=None, names=['songs'])\\\n",
    "    .assign(songs=lambda df: df.songs.str.split(' ')\\\n",
    "    .apply(lambda ids: list(map(int, filter(None, ids)))))\\\n",
    "    .iloc[FIRST_FAULTY_PLAYLIST:,:]\n",
    "\n",
    "print('{} playlists for a total of {} songs'.format(playlists.shape[0], playlists.songs.apply(len).sum()))\n",
    "playlists.head()\n",
    "playlists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .DataFrame.from_records\n",
    "* chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175911, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>position</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  position  song_id\n",
       "0            2         0        0\n",
       "1            2         1        1\n",
       "2            2         2        2\n",
       "3            2         3        3\n",
       "4            2         4        4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "playlist_songs = pd.DataFrame.from_records(\n",
    "    data=chain.from_iterable([(playlist_id, position, song_id) for position, song_id in enumerate(song_ids)] for playlist_id, (song_ids,) in playlists.iterrows()),\n",
    "    columns=['playlist_id', 'position', 'song_id'])\n",
    "\n",
    "print(playlist_songs.shape)\n",
    "playlist_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389728 playlists for a total of 1581007 songs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3, 30, 38, 11, 39, 22, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 41, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[43, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         songs\n",
       "2  [3, 30, 38, 11, 39, 22, 40]\n",
       "3                 [12, 41, 42]\n",
       "4                     [43, 36]\n",
       "5                         [44]\n",
       "6                          [4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_playlists = pd.read_csv('dataset/yes_small/test.txt', header=None, names=['songs'])\\\n",
    "    .assign(songs=lambda df: df.songs.str.split(' ').apply(lambda ids: list(map(int, filter(None, ids)))))\\\n",
    "    .iloc[FIRST_FAULTY_PLAYLIST:,:]\n",
    "\n",
    "print('{} playlists for a total of {} songs'.format(test_playlists.shape[0], test_playlists.songs.apply(len).sum()))\n",
    "test_playlists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cat.codes?\n",
    "* set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gucci Time (w\\/ Swizz Beatz)</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aston Martin Music (w\\/ Drake &amp; Chrisette Mich...</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Back Up (w\\/ Chris Brown)</td>\n",
       "      <td>T.I.</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot Toddy (w\\/ Jay-Z &amp; Ester Dean)</td>\n",
       "      <td>Usher</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whip My Hair</td>\n",
       "      <td>Willow</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         song_id                                              title  \\\n",
       "song_id                                                               \n",
       "0              0                       Gucci Time (w\\/ Swizz Beatz)   \n",
       "1              1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   \n",
       "2              2                      Get Back Up (w\\/ Chris Brown)   \n",
       "3              3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)   \n",
       "4              4                                       Whip My Hair   \n",
       "\n",
       "             artist  artist_id  \n",
       "song_id                         \n",
       "0        Gucci Mane        474  \n",
       "1         Rick Ross        960  \n",
       "2              T.I.       1098  \n",
       "3             Usher       1264  \n",
       "4            Willow       1304  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv('dataset/yes_small/song_hash.txt', sep='\\t', names=['song_id', 'title', 'artist'])\\\n",
    "    .set_index('song_id', drop=False)\\\n",
    "    .assign(artist_id=lambda df: df.artist.astype('category').cat.codes)\n",
    "\n",
    "print(songs.shape)\n",
    "songs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num songs by artist\n",
    "\n",
    "* groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10 Years</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id        artist  n_songs_played\n",
       "0          0             -              93\n",
       "1          1   .38 Special              47\n",
       "2          2      10 Years             152\n",
       "3          3          2Pac             146\n",
       "4          4  3 Doors Down             274"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = songs.groupby('artist_id').first()[['artist']].reset_index()\n",
    "\n",
    "artist_songs_played = songs.artist.loc[playlist_songs.song_id].to_frame('artist')\\\n",
    "    .groupby('artist').size()\\\n",
    "    .sort_values(ascending=False).to_frame('n_songs_played')\n",
    "\n",
    "artists = pd.merge(artists, artist_songs_played.reset_index(), on='artist')\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .merge\n",
    "* plt.hist, plt.xscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>position</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>All I Wants Is You (w\\/ J Cole)</td>\n",
       "      <td>Miguel</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Champagne Life</td>\n",
       "      <td>Ne-Yo</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Find Your Love</td>\n",
       "      <td>Drake</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Your Love</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  position  song_id                            title  \\\n",
       "0            4         0       12  All I Wants Is You (w\\/ J Cole)   \n",
       "1            4         1       13                   Champagne Life   \n",
       "2            4         2       14                   Find Your Love   \n",
       "3            4         3       15                        Your Love   \n",
       "\n",
       "        artist  artist_id  \n",
       "0       Miguel        797  \n",
       "1        Ne-Yo        832  \n",
       "2        Drake        341  \n",
       "3  Nicki Minaj        844  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116bfd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(playlist_songs.groupby('playlist_id').size(), bins=np.logspace(0, 3, 30))\n",
    "plt.xscale('log')\n",
    "\n",
    "pd.merge(\n",
    "    playlist_songs.query('playlist_id == 4'),\n",
    "    songs,\n",
    "    on='song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3168.000000\n",
       "mean     1583.500000\n",
       "std       914.667153\n",
       "min         0.000000\n",
       "25%       791.750000\n",
       "50%      1583.500000\n",
       "75%      2375.250000\n",
       "max      3167.000000\n",
       "Name: song_id, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.song_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    175911.000000\n",
       "mean       1532.231151\n",
       "std        1016.879762\n",
       "min           0.000000\n",
       "25%         541.000000\n",
       "50%        1579.000000\n",
       "75%        2505.000000\n",
       "max        3167.000000\n",
       "Name: song_id, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "playlist_songs.song_id.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram generator\n",
    "Generating all pairs of co-played words (ie artists) from the same context (ie playlist), without taking into account the order.\n",
    "\n",
    "* permutations, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_id\n",
      "9      965\n",
      "10     394\n",
      "11    1264\n",
      "Name: artist_id, dtype: int16\n",
      "[(965, 394), (965, 1264), (394, 965), (394, 1264), (1264, 965), (1264, 394)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, chain\n",
    "\n",
    "song_ids = playlist_songs.query('playlist_id == 3').song_id.values\n",
    "\n",
    "def artist_skip_grams(song_ids):\n",
    "    song_artist_ids = songs.artist_id.loc[song_ids].values\n",
    "    return [(a1, a2) for a1, a2 in permutations(song_artist_ids, 2) if a1 != a2]\n",
    "\n",
    "print(songs.artist_id.loc[song_ids])\n",
    "print(artist_skip_grams(song_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SONGS = songs.song_id.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* chain.from_iterable map\n",
    "* repeat\n",
    "* islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice, repeat\n",
    "\n",
    "class PlaylistToArtistSkipGrams:\n",
    "\n",
    "    def __init__(self, playlists=playlists, loops=1):\n",
    "        all_artist_skip_grams = chain.from_iterable(map(artist_skip_grams, playlists.songs.values))\n",
    "        self.all_artist_skip_grams_iterable = chain.from_iterable(repeat(all_artist_skip_grams, loops))\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        next_skip_grams = list(islice(self.all_artist_skip_grams_iterable, batch_size))\n",
    "        return np.array(next_skip_grams, dtype=np.int32) \n",
    "\n",
    "skipGramGenerator = PlaylistToArtistSkipGrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = PlaylistToArtistSkipGrams(playlists=playlists, loops=1)\n",
    "# print(input_data.next_batch(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram model in Tensorflow\n",
    "\n",
    "The implementation in tutorial uses some high-level optimised function (namely the tf.nn.nce_loss) that makes the code less didactic without having any impact for the size of our dataset.\n",
    "Therefore it's a better exercise to:\n",
    "* Define input_embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) and the symmetrical hidden_embeddings (instead of nce_weights) as in the schema below\n",
    "* Drop the nce_biases altogether\n",
    "* Multiply the embed tensor with the hidden_embeddings to calculate a (N_SAMPLES x N_OUTPUT_SONGS) logits tensor (hint: use tf.matmul and tf.transpose)\n",
    "* Feed logits and train_labels into tf.nn.sparse_softmax_cross_entropy_with_logits as we did for the iris classification\n",
    "* (Or alternatively compute manually the softmax loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://adriancolyer.files.wordpress.com/2016/04/word2vec-skip-gram.png?w=1132\" width=\"400\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://adriancolyer.files.wordpress.com/2016/04/word2vec-skip-gram.png?w=1132\", width=400, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math \n",
    "vocabulary_size = songs.shape[0]\n",
    "embedding_size = 50\n",
    "\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "nce_weights = tf.Variable(\n",
    "  tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                      stddev=1.0 / math.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# Placeholders for inputs\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sampled = 50\n",
    "# Compute the NCE loss, using a sample of the negative labels each time.\n",
    "loss = tf.reduce_mean(\n",
    "  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n",
    "                 num_sampled, vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use the SGD optimizer.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c06cdca5c97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "for inputs, labels in a.next_batch(batch_size):\n",
    "    feed_dict = {train_inputs: inputs, train_labels: labels}\n",
    "    _, cur_loss = sess.run([optimizer, loss], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next session: \n",
    "* Implement word2vec (as FFN) in Keras\n",
    "* using the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Reshape, Dense, Activation\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=1))\n",
    "# (None, 3168) but got array with shape (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Reshape((embedding_size,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Dense(output_dim=vocabulary_size, input_dim=embedding_size))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected activation_2 to have shape (None, 3168) but got array with shape (2, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ae5a4d483fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/olegshevelev/Soft/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    765\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/olegshevelev/Soft/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/olegshevelev/Soft/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1035\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m   1036\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/Users/olegshevelev/Soft/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected activation_2 to have shape (None, 3168) but got array with shape (2, 1)"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "current_batch = train_data.next_batch(batch_size)\n",
    "input_data = current_batch[0]\n",
    "output_data = current_batch[1]\n",
    "\n",
    "model.train_on_batch(input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
