{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 newsgroups dataset shows NMF parts-based decomposition\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'sci.space',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'talk.politics.guns', 'sci.space', 'talk.politics.misc']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2461,)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2461,)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 1, 4, 0, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10] #  The target attribute is the integer index of the category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vectors from train set using CountVectorizer\n",
    "See http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.9, min_df=0.01)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2461x1465 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93788 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['text', 'document', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father',\n",
       " 'fault',\n",
       " 'fbi',\n",
       " 'fear',\n",
       " 'federal',\n",
       " 'feds',\n",
       " 'feel',\n",
       " 'feet',\n",
       " 'field',\n",
       " 'fight']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[500:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('attitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['completely', 'new'], \n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "sparse_array_of_features = vectorizer.transform(['Something completely new.'])\n",
    "#feature_names[sparse_array_of_features.toarray().nonzero()[1]]\n",
    "feature_names[sparse_array_of_features.tocoo().col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.10971149939049"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract components using NMF from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=10)\n",
    "model.fit(vectors)\n",
    "vectors_transformed = model.transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1465)\n"
     ]
    }
   ],
   "source": [
    "print(model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557.53214316718129"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reconsruction_error(X, reconstructed_X):\n",
    "    return np.sqrt(np.power((X - reconstructed_X), 2).sum())\n",
    "    \n",
    "reconsruction_error(\n",
    "    X,\n",
    "    reconstructed_X=vectors_transformed.dot(model.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['united' 'firearms' 'states' 'congress' 'mr' 'file' 'gun' 'control']\n",
      "['did' 'said' 'think' 'mr' 'know' 'going' 'don' 'president']\n",
      "['earth' 'shuttle' 'information' 'available' 'edu' 'nasa' 'space' 'lunar']\n",
      "['believe' 'religious' 'god' 'atheism' 'true' 'does' 'people' 'atheists']\n",
      "['program' 'american' 'government' 'think' 'official' 'russian' 'president'\n",
      " 'administration']\n",
      "['plan' 'nuclear' 'time' 'british' 'war' 'south' 'military' 'new']\n",
      "['course' 'david' 'said' 'king' 'lord' 'people' 'jesus' 'matthew']\n",
      "['secretary' 'school' 'want' 'summer' 'young' 'people' 'jobs' 'work']\n",
      "['market' 'services' 'year' 'satellites' 'commercial' 'satellite' 'launch'\n",
      " 'space']\n",
      "['person' 'license' 'shall' 'dangerous' 'military' 'firearm' 'section'\n",
      " 'weapon']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "for component in model.components_:\n",
    "    indices = np.argpartition(component, -10)[-8:] # take 10 words with biggest value    \n",
    "    print(feature_names[indices])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00170674,  0.03223594,  0.        ,  0.07593279,  0.        ,\n",
       "         0.00189783,  0.0280003 ,  0.12034452,  0.        ,  0.07487013]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vectors from train set using CountVectorizer with bi-grams of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1,5), \n",
    "                                    stop_words='english', max_df=0.95, min_df=0.001)\n",
    "analyze = bigram_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze('Bi-grams are cool!') == (['bi grams', 'grams cool', 'bi grams cool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2461x18895 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 196207 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectors = bigram_vectorizer.fit_transform(newsgroups_train.data)\n",
    "bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18895"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['415',\n",
       " '415 864',\n",
       " '415 864 0952',\n",
       " '415 864 0952 fax',\n",
       " '415 864 0952 fax 415',\n",
       " '415 864 7506',\n",
       " '415 864 7506 71034',\n",
       " '415 864 7506 71034 2711',\n",
       " '416',\n",
       " '42']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.get_feature_names()[500:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.72653392929703"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectors.nnz / float(bigram_vectors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "bigram_model = NMF(n_components=10)\n",
    "bigram_model.fit(bigram_vectors)\n",
    "bigram_vectors_transformed = bigram_model.transform(bigram_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 18895)\n"
     ]
    }
   ],
   "source": [
    "print(bigram_model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['don know' 'said' 'think' 'going' 'know' 'president' 'mr stephanopoulos'\n",
      " 'mr' 'stephanopoulos' 'don']\n",
      "['rkba' 'control' 'gun' 'gun control' 'mr' 'file' 'congress' 'firearms'\n",
      " 'united' 'states']\n",
      "['people' 'believe' 'true' 'religion' 'does' 'argument' 'religious' 'god'\n",
      " 'atheism' 'atheists']\n",
      "['launches' 'data' 'year' 'services' 'satellites' 'satellite' 'market'\n",
      " 'commercial' 'space' 'launch']\n",
      "['american' 'president' 'government' 'administration' 'official' 'russian'\n",
      " 'program' 'senior' 'russia' 'think']\n",
      "['ships' 'naval' 'georgia' 'secret' 'island' 'nuclear' 'military' 'new'\n",
      " 'south' 'war']\n",
      "['king' 'lord' 'david' 'isaiah' 'messiah' 'jesus' 'prophecy' 'matthew'\n",
      " 'people' 'said']\n",
      "['mars' 'earth' 'shuttle' 'data' 'lunar' 'information' 'available' 'edu'\n",
      " 'nasa' 'space']\n",
      "['said' 'don' 'll' 'think' 'dee' 'going' 'options' 'package' 'president'\n",
      " 'ms']\n",
      "['secretary' 'want' 'think' 'school' 'young people' 'summer' 'jobs'\n",
      " 'people' 'young' 'work']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(bigram_vectorizer.get_feature_names())\n",
    "\n",
    "for component in bigram_model.components_:\n",
    "    indices = np.argpartition(component, -10)[-10:] # take 10 words with biggest value    \n",
    "    print(feature_names[indices])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras for NNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n",
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.layers import Embedding, Reshape, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import nonneg\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "X = vectors\n",
    "n_texts, n_words = X.shape\n",
    "embedding_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "weights_contraint = nonneg()\n",
    "text_to_embedding = Embedding(n_texts, embedding_size, input_length=1, W_constraint=weights_contraint)\n",
    "model.add(text_to_embedding)\n",
    "model.add(Reshape((embedding_size,)))\n",
    "model.add(Dense(output_dim=n_words, input_dim=embedding_size, bias=False, W_constraint=weights_contraint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1004)\t1\n",
      "  (0, 1291)\t1\n",
      "  (0, 731)\t1\n",
      "  (0, 811)\t1\n",
      "  (0, 106)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00046321, -0.00295585, -0.00397265, ..., -0.00422178,\n",
       "         0.00104016,  0.00144252]], dtype=float32)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[1])\n",
    "model.predict(np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error') # the way you compare the ground truth and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2458, 2459, 2460])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_ids = np.arange(n_texts)\n",
    "X_text_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a653780>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_text_ids, y=X.toarray(), batch_size=256, verbose=0, nb_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760.7298891632098"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconsruction_error(\n",
    "    X,\n",
    "    reconstructed_X=model.predict(X_text_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['god' 'believe' 'know' 'don' 'evidence' 'mr' 'president' 'does']\n",
      "['president' 'know' 'does' 'jesus' 'bible' 'christian' 'mr' 'god']\n",
      "['faq' 'send' 'president' 'space' 'information' 'edu' 'nasa' 'mr']\n",
      "['know' 'mr' 'good' 'like' 'think' 'people' 'just' 'don']\n",
      "['going' 'work' 'year' 'mr' 'nasa' 'president' 'space' 'program']\n",
      "['don' 'people' 'think' 'know' 'going' 'did' 'mr' 'president']\n",
      "['work' 'know' 'going' 'think' 'mr' 'people' 'president' 'jobs']\n",
      "['study' '000' 'new' 'gun' 'guns' 'mr' 'firearms' 'weapons']\n",
      "['know' 'don' 'think' 'states' 'mr' 'does' 'state' 'president']\n",
      "['orbit' 'mission' 'satellite' 'data' 'nasa' 'shuttle' 'earth' 'space']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "for component in model.layers[2].weights[0].eval():\n",
    "    indices = np.argpartition(component, -10)[-8:]\n",
    "    print(feature_names[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
